---
layout: post
title: "Использование Docker для кросскомпиляции проектов"
permalink: docker-cpp
tags: C++ docker
---

![]({{ site.baseurl }}assets/2017-05-15-docker-c++/cplus-docker.jpg)  
Четкая короткая фраза :)

---

## Содержание
- [Проблема](#problem)
- [Постановка задачи](#formulation)
- [Решение](#solution)
    - [Docker](#docker)
    - [Docker Registry](#registry)
- [Заключение](#resume)

## Проблема    {#problem}
Сколько времени должен потратить новый сотрудник на то, чтобы собрать не знакомый ему проект? Обычно на это отвечают подобным образом: суммарное время необходимое на следующие действия:
 - выкачать/склонировать репозиторий проекта;
 - установить/настроить средства разработки(тулчейн, IDE, библиотеки);
 - разложить все по правильным путям, сконфигурировать make/cmake/qmake-файл/project_build.sh для сборки;
 - запустить саму сборку. 

По дороге может выясниться что где-то чего-то не хватает в зависимостях, неправильно прописан путь к либе/утилите/тулчейну, не та версия библиотеки стоит в системе. И пока решишь все эти мелкие проблемы - пройдет значительный кусок времени. Плюс еще по любому будут привлекаться сотрудники, которые уже давно работают с проектом.

Обычно для того что бы каждый раз не набивать шишки - пишеться некий README, где прописываються точные инструкции, по выполнению которых можно добиться воспроизводимого результата. За пару человек эти инструкции отлаживаються и наступает счастье.

В идеале хочеться чтобы сборка проекта выглядела подобным образом:  

{% highlight bash %}
    install all required software, SDKs, libs
    git clone git@project.git
    cd project_dir
    make/cmake/build_project.sh
{% endhighlight %}

Дальнейший шаг - инструкции из README автоматизируются скриптом.

Ок, подобный подход можно реализовать, если проект собирается под одну платформу/ОС.
Но представим следующую ситуацию:
 - есть n-ное количество целевых платформ, под который проект собирается, соответсвенно разные тулчейны для кросскомпиляции
 - под каждый конкретный процессор идет собственное SDK от чипмейкера. Есть различные версии одного и того же SDK.
 - в SDK находяться баги, их патчат, соотв. необходимо SDK пересобирать, бинари расшарить между разработчиками
 - тоже самое касается еще ряда библиотек, которые работают поверх SDK, например, Qt
 - необходимо свести к минимуму время на развертывание окружения для разработки под конкретную платформу
 - большинству разработчиков вообще не надо/не интересно заморачиваться окружением, им бы сразу попасть в готовое, где можно писать уже непосредственно код
 - весь зоопарк платфом надо как-то тестировать, желательно автоматически, хотя бы на предмет того что код проекта успешно компилируется под все платформы.

Какие варианты решений я встречал/проходил:
 - каждый сам себе все настраивает: долго, не воспроизводимо(проблема "у меня на компьютере все работает", так как у каждого разработчика разное окружение), подверженно ошибкам конфигураций. При выпуске новой версии SDK - прохождение квеста каждым разработчиком заново. Автоматизация сборки всего shell скриптом может частично решить проблему;
 - единное окружение у всех разработчиков, варианты обеспечения:
    - единожды настроенная виртуальная машина билмастером, все ее себе копируют и работают локально. Новое SDK/библиотека/что-то пропатчено/какое-то важное изменение - новая виртуалка. Тяжело, много места, неудобно;
    - настроенные сервера, у каждого есть свой аккаунт, все туда логиняться по ssh, у каждого своя копия исходников, которая подмонтирована на локальную машину разработчика по samba/nfs/sshfs/whatever, и все собираются в уже готовом и настроенном окружении. Сеть/сервер упали - разработчики ковыряются в носу. Качество работы определяется качеством работы сети, в целом невысокая производительность работы IDE(парсинг проекта) так как сеть в любом случае проигрывает в скорости диску. Очень острожно надо менять настройки окружения, ибо если накосячить случайно - зацепит всех, не классно;
    - [linux контейнеры](https://ru.wikipedia.org/wiki/Виртуализация_на_уровне_операционной_системы) - об этом и поговорим далее.

## Постановка задачи    {#formulation}

Вкратце задача звучит так: хочеться иметь контейнер, который содержит внутри себя все необходимое для разработки под конкретную платформу. Чтобы его мог скопировать себе на машину любой разработчик и тут же начать работать. Ведь несомненно проще скопировать и запустить, чем проходить квест по настройке окружения в соответсвии с README проекта. N платформ - N контейнеров. Также было бы классно, чтобы разработчики не бегали с флешками/ходили по сети к билдмастеру, а как-то имели возможность централизовано получать интересующие их контейнеры. Из всех вариантов(LXC, OpenVZ, и т.д.), которые были доступны на данный момент, лишь Docker подошел полностью.

## Решение  {#solution}

### Docker  {#docker}

Docker simplifies the packaging, distribution, installation and execution of (complex) applications.

In this context, applications are:

blogging platforms like Wordpress or Ghost
tools for software collaboration like Gitlab or Gogs
file synchronization platforms like OwnCloud or Seafile
These kinds of applications usually consist of many components which need to be installed and configured. This is often a time consuming and frustrating experience for users.

Есть четыре класса задач, для которых Docker пoдходит если не идеально, то лучше любого другого инструмента. Это:
 - Упрощение процеcса разворачивания/сопровождения проектов. Docker позволяет разбить пpоект на небольшие независимые, удобные в сопровождении кoмпоненты, работать с которыми гораздо комфортнее, чем с реальными сущностями вроде Apache 2.4.12, установленного на хосте 1.2.3.4, работающем под управлениeм CentOS 6.
 - Continous development и zero-downtime deployment. Каждый образ Docker — вещь в себе, включающая сервис (или набор сервисов), окружение для его запуска и нeобходимые настройки. Поэтому контейнеры можно передавать между членaми команды в ходе цикла «разработка -> тестирование -> внедрение» и быстро внeдрять изменения, просто переключая настройки на новые контейнеры.
 - IaaS/PaaS. Блaгодаря легковесности контейнеров Docker можно испoльзовать в качестве движка виртуализации в IaaS, а благодаря проcтоте миграции Docker становится идеальным решением для запуска сервисов в PaaS.
 - Запуск небезопaсного кода. Docker позволяет запустить любой, в том числе графический софт внутри изoлированного контейнера с помощью одной простой команды. Поэтому он идеально подходит для запуска разного рода недовереннoго или просто небезопасного кода.


У Docker следующие преимущества перед вышеперечисленными вариантами:
 - виртуализация на уровне операционной системы, а это значит минимальные потери производительности, легковесность в сравнении с полноценной виртуалкой;
 - позволяет «упаковать» приложение со всем его окружением и зависимостями в контейнер, который может быть перенесён на любую Linux-систему с поддержкой [cgroups](https://ru.wikipedia.org/wiki/Cgroups) в [ядре](https://ru.wikipedia.org/wiki/Ядро_Linux)
 - версионирование
 - изоляция. В системе одна версия библиотеки, в контейнере другая. Впринципе можно на Ubuntu запустить CentOS/Gentoo/etc.
 - вообще круто использовать docker для эксперементов - позволяет не засорять систему в процессе разработки/тестирования
 - дистрибьюция контейнеров - сервер [Docker Registry](#registry), у других контейнеров не нашел такой удобной фишки.


Контейнеры идеальны для автоматического тестирования. Каждый тест можно в своей песочнице запускать


### Docker Registry {#registry}

[Docker Hub](hub.docker.com) - аналог Github в мире docker контейнеров. Там можно размещать неограниченное количество публичных образов и только один приватный. Большее количество приватных образов можно добавлять за отдельную плату. Если нет ничего секретного - заводим аккаунт, выкладываем образы, которые публичны и доступны всем. Можно купить подписку и размещать приватные образа, т.е. публично не доступные. Эти два варианты клевые тем, что сразу снимается вопрос поддержки, за нас это делают админы Docker Hub.
Если хочеться приватности(например, внутри контейнера размещены компоненты третьих сторон, NDA которых запрещает хранение за пределами инфрастуктуры компании-пользователя) - подымаем [Docker Registry](https://docs.docker.com/registry/). Docker Registry это не тоже самое что Docker Hub, т.е. мы не получим хранилище контейнеров с красивым веб-интерфейсом.

Docker Registry - это хранилище с версионированными docker образами. Регистр удобно использовать как единную точку хранения и раздачи контейнеров внутри компании.
По умолчанию Docker всегда "смотрит" на Docker Hub. Для того что бы он мог работать с другим хранилищем, надо его адрес добавить в /etc/docker/daemon.json:
{% highlight bash %}
    docker push registry_ip:registry_port/image_name:image_version
{% endhighlight %}

[Docker Registry](https://docs.docker.com/registry/)

прописываем адрес Docker Registry в /etc/docker/daemon.json


Схема работы такова:
 - на рабочем компьютере билдмастера собирается образ, который содержит все необходимое для разработки под конкретную платформу, и отправляется в регистр:
{% highlight bash %}
    docker push registry_ip:registry_port/image_name:image_version
{% endhighlight %}
 - все желающие забирают/пулят образ из регистра и работают в готовом окружении:
{% highlight bash %}
    docker pull registry_ip:registry_port/image_name:image_version
{% endhighlight %}


запуск:
{% highlight bash %}
    docker run -it --rm -v /path/to/project/sources:/path/of/sources/inside/container registry_ip:registry_port/image_name:image_version bash
{% endhighlight %}
В результате получаем обычную командную строку(в данном случае bash), в которой можно перейти в папку с проектом и вызвать make/cmake/build.sh
Можно запустить сразу билд, что бы ручками не ходить куда-то:

{% highlight bash %}
    docker run -it --rm -v /path/to/project/sources:/path/of/sources/inside/container registry_ip:registry_port/image_name:image_version bash -c "cd /path/of/sources/inside/container; make/cmake/build.sh;"
{% endhighlight %}
Команду выше можно использовать для интеграции с IDE: в каждой приличной IDE есть что-то вроде custom build steps, куда приведенную команду можно прописать.




## Заключение   {#resume}
